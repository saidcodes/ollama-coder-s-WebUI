# Ollama Coder's Interface

A simple interface to run and interact with AI models locally using Ollama.

## Prerequisites

- [Node.js](https://nodejs.org/)
- [Ollama](https://ollama.com/) installed and at least one model downloaded

## Getting Started

1. **Install dependencies:**

   ```
   npm install
   ```

2. **Ensure Ollama is running** and you have downloaded at least one model.

3. **Start the development server:**

   ```
   npm run dev
   ```

4. Open your browser and enjoy your local AI chat web UI!

## Notes

- For more information on Ollama, visit [Ollama Documentation](https://ollama.com/docs).
- If you encounter issues, check that Ollama is running and accessible on its default port.
